{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>NDWI</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>MNDWI</th>\n",
       "      <th>WRI</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>AWEI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206</td>\n",
       "      <td>439</td>\n",
       "      <td>275</td>\n",
       "      <td>860</td>\n",
       "      <td>2306</td>\n",
       "      <td>2934</td>\n",
       "      <td>2619</td>\n",
       "      <td>3185</td>\n",
       "      <td>1551</td>\n",
       "      <td>762</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.712884</td>\n",
       "      <td>0.256115</td>\n",
       "      <td>-0.558794</td>\n",
       "      <td>0.171223</td>\n",
       "      <td>0.809952</td>\n",
       "      <td>-7198.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216</td>\n",
       "      <td>390</td>\n",
       "      <td>326</td>\n",
       "      <td>672</td>\n",
       "      <td>1526</td>\n",
       "      <td>1774</td>\n",
       "      <td>2144</td>\n",
       "      <td>2075</td>\n",
       "      <td>1218</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.692186</td>\n",
       "      <td>0.275431</td>\n",
       "      <td>-0.514925</td>\n",
       "      <td>0.212968</td>\n",
       "      <td>0.736032</td>\n",
       "      <td>-5432.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>170</td>\n",
       "      <td>377</td>\n",
       "      <td>266</td>\n",
       "      <td>732</td>\n",
       "      <td>1807</td>\n",
       "      <td>2122</td>\n",
       "      <td>2146</td>\n",
       "      <td>2391</td>\n",
       "      <td>1287</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.701149</td>\n",
       "      <td>0.250218</td>\n",
       "      <td>-0.546875</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.779436</td>\n",
       "      <td>-5942.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>247</td>\n",
       "      <td>558</td>\n",
       "      <td>414</td>\n",
       "      <td>1082</td>\n",
       "      <td>2273</td>\n",
       "      <td>2564</td>\n",
       "      <td>2601</td>\n",
       "      <td>2925</td>\n",
       "      <td>2124</td>\n",
       "      <td>1084</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.646724</td>\n",
       "      <td>0.100952</td>\n",
       "      <td>-0.583893</td>\n",
       "      <td>0.205714</td>\n",
       "      <td>0.725373</td>\n",
       "      <td>-9895.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194</td>\n",
       "      <td>496</td>\n",
       "      <td>378</td>\n",
       "      <td>905</td>\n",
       "      <td>1896</td>\n",
       "      <td>2204</td>\n",
       "      <td>2602</td>\n",
       "      <td>2571</td>\n",
       "      <td>1739</td>\n",
       "      <td>828</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.679793</td>\n",
       "      <td>0.198802</td>\n",
       "      <td>-0.556152</td>\n",
       "      <td>0.201336</td>\n",
       "      <td>0.746309</td>\n",
       "      <td>-7899.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538078</th>\n",
       "      <td>632</td>\n",
       "      <td>835</td>\n",
       "      <td>1114</td>\n",
       "      <td>1219</td>\n",
       "      <td>1015</td>\n",
       "      <td>1007</td>\n",
       "      <td>1256</td>\n",
       "      <td>1062</td>\n",
       "      <td>729</td>\n",
       "      <td>505</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.201339</td>\n",
       "      <td>0.265491</td>\n",
       "      <td>0.067775</td>\n",
       "      <td>0.981864</td>\n",
       "      <td>0.059916</td>\n",
       "      <td>-1278.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538079</th>\n",
       "      <td>626</td>\n",
       "      <td>944</td>\n",
       "      <td>1078</td>\n",
       "      <td>992</td>\n",
       "      <td>427</td>\n",
       "      <td>375</td>\n",
       "      <td>323</td>\n",
       "      <td>214</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490134</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.932446</td>\n",
       "      <td>5.679775</td>\n",
       "      <td>-0.538901</td>\n",
       "      <td>3472.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538080</th>\n",
       "      <td>646</td>\n",
       "      <td>968</td>\n",
       "      <td>1106</td>\n",
       "      <td>1001</td>\n",
       "      <td>437</td>\n",
       "      <td>408</td>\n",
       "      <td>344</td>\n",
       "      <td>203</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>0.750636</td>\n",
       "      <td>0.903638</td>\n",
       "      <td>5.277354</td>\n",
       "      <td>-0.525517</td>\n",
       "      <td>3493.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538081</th>\n",
       "      <td>605</td>\n",
       "      <td>904</td>\n",
       "      <td>1036</td>\n",
       "      <td>922</td>\n",
       "      <td>394</td>\n",
       "      <td>353</td>\n",
       "      <td>287</td>\n",
       "      <td>192</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518052</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.929562</td>\n",
       "      <td>6.062500</td>\n",
       "      <td>-0.566138</td>\n",
       "      <td>3332.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538082</th>\n",
       "      <td>620</td>\n",
       "      <td>902</td>\n",
       "      <td>973</td>\n",
       "      <td>870</td>\n",
       "      <td>372</td>\n",
       "      <td>323</td>\n",
       "      <td>273</td>\n",
       "      <td>171</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.535319</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.933548</td>\n",
       "      <td>6.167763</td>\n",
       "      <td>-0.561798</td>\n",
       "      <td>3325.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538083 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1     2     3     4     5     6     7     8     9  10  \\\n",
       "0       206  439   275   860  2306  2934  2619  3185  1551   762   0   \n",
       "1       216  390   326   672  1526  1774  2144  2075  1218   576   0   \n",
       "2       170  377   266   732  1807  2122  2146  2391  1287   642   0   \n",
       "3       247  558   414  1082  2273  2564  2601  2925  2124  1084   0   \n",
       "4       194  496   378   905  1896  2204  2602  2571  1739   828   0   \n",
       "...     ...  ...   ...   ...   ...   ...   ...   ...   ...   ...  ..   \n",
       "538078  632  835  1114  1219  1015  1007  1256  1062   729   505   1   \n",
       "538079  626  944  1078   992   427   375   323   214    33    33   1   \n",
       "538080  646  968  1106  1001   437   408   344   203    49    35   1   \n",
       "538081  605  904  1036   922   394   353   287   192    33    29   1   \n",
       "538082  620  902   973   870   372   323   273   171    31    33   1   \n",
       "\n",
       "            NDWI      NDMI     MNDWI       WRI      NDVI     AWEI  \n",
       "0      -0.712884  0.256115 -0.558794  0.171223  0.809952 -7198.25  \n",
       "1      -0.692186  0.275431 -0.514925  0.212968  0.736032 -5432.00  \n",
       "2      -0.701149  0.250218 -0.546875  0.187300  0.779436 -5942.00  \n",
       "3      -0.646724  0.100952 -0.583893  0.205714  0.725373 -9895.25  \n",
       "4      -0.679793  0.198802 -0.556152  0.201336  0.746309 -7899.50  \n",
       "...          ...       ...       ...       ...       ...      ...  \n",
       "538078 -0.201339  0.265491  0.067775  0.981864  0.059916 -1278.75  \n",
       "538079  0.490134  0.814607  0.932446  5.679775 -0.538901  3472.50  \n",
       "538080  0.475610  0.750636  0.903638  5.277354 -0.525517  3493.75  \n",
       "538081  0.518052  0.793750  0.929562  6.062500 -0.566138  3332.50  \n",
       "538082  0.535319  0.796053  0.933548  6.167763 -0.561798  3325.00  \n",
       "\n",
       "[538083 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('filtered_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение признаков и целевой переменной\n",
    "X = df.iloc[:, :10].join(df[['NDWI', 'NDMI', 'MNDWI', 'WRI', 'NDVI', 'AWEI']])  # Признаки: все колонки от 0 до 9 + новые\n",
    "y = df.iloc[:, 10]   # Целевая переменная: колонка \"water\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost:\n",
      "\n",
      "Training Time: 3.66 seconds\n",
      "Confusion Matrix:\n",
      "[[103766    243]\n",
      " [   520   3088]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    104009\n",
      "           1       0.93      0.86      0.89      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.96      0.93      0.94    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asas7\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "\n",
      "Training Time: 25.76 seconds\n",
      "Confusion Matrix:\n",
      "[[103845    164]\n",
      " [   742   2866]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    104009\n",
      "           1       0.95      0.79      0.86      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.97      0.90      0.93    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n",
      "\n",
      "Decision Tree:\n",
      "\n",
      "Training Time: 21.58 seconds\n",
      "Confusion Matrix:\n",
      "[[103426    583]\n",
      " [   586   3022]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    104009\n",
      "           1       0.84      0.84      0.84      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.92      0.92      0.92    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "\n",
      "Training Time: 331.85 seconds\n",
      "Confusion Matrix:\n",
      "[[103789    220]\n",
      " [   519   3089]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    104009\n",
      "           1       0.93      0.86      0.89      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.96      0.93      0.94    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "\n",
      "Training Time: 230.18 seconds\n",
      "Confusion Matrix:\n",
      "[[103770    239]\n",
      " [   533   3075]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    104009\n",
      "           1       0.93      0.85      0.89      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.96      0.92      0.94    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n",
      "\n",
      "K-Nearest Neighbors:\n",
      "\n",
      "Training Time: 0.06 seconds\n",
      "Confusion Matrix:\n",
      "[[103775    234]\n",
      " [   535   3073]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    104009\n",
      "           1       0.93      0.85      0.89      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.96      0.92      0.94    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6, verbose=0),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Обучение и оценка каждой модели\n",
    "for name, model in models.items():\n",
    "    start_time = time()  # Начало измерения времени\n",
    "    model.fit(X_train, y_train)  # Обучение модели\n",
    "    end_time = time()  # Конец измерения времени\n",
    "    \n",
    "    # Предсказание на тестовом наборе\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Оценка производительности модели\n",
    "    print(f\"\\n{name}:\\n\")\n",
    "    print(f\"Training Time: {end_time - start_time:.2f} seconds\")  # Время обучения\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import tempfile\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost:\n",
      "\n",
      "Training Time: 3.52 seconds\n",
      "Confusion Matrix:\n",
      "[[103766    243]\n",
      " [   520   3088]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    104009\n",
      "           1       0.93      0.86      0.89      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.96      0.93      0.94    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\asas7\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "\n",
      "Training Time: 27.14 seconds\n",
      "Confusion Matrix:\n",
      "[[103845    164]\n",
      " [   742   2866]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    104009\n",
      "           1       0.95      0.79      0.86      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.97      0.90      0.93    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n",
      "\n",
      "Decision Tree:\n",
      "\n",
      "Training Time: 20.74 seconds\n",
      "Confusion Matrix:\n",
      "[[103421    588]\n",
      " [   593   3015]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    104009\n",
      "           1       0.84      0.84      0.84      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.92      0.91      0.92    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "\n",
      "Training Time: 333.17 seconds\n",
      "Confusion Matrix:\n",
      "[[103778    231]\n",
      " [   522   3086]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    104009\n",
      "           1       0.93      0.86      0.89      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.96      0.93      0.94    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n",
      "\n",
      "Gradient Boosting:\n",
      "\n",
      "Training Time: 238.24 seconds\n",
      "Confusion Matrix:\n",
      "[[103775    234]\n",
      " [   538   3070]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    104009\n",
      "           1       0.93      0.85      0.89      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.96      0.92      0.94    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n",
      "\n",
      "K-Nearest Neighbors:\n",
      "\n",
      "Training Time: 0.06 seconds\n",
      "Confusion Matrix:\n",
      "[[103775    234]\n",
      " [   535   3073]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    104009\n",
      "           1       0.93      0.85      0.89      3608\n",
      "\n",
      "    accuracy                           0.99    107617\n",
      "   macro avg       0.96      0.92      0.94    107617\n",
      "weighted avg       0.99      0.99      0.99    107617\n",
      "\n",
      "\n",
      "Model Sizes (in MB):\n",
      "CatBoost: 0.11 MB\n",
      "Logistic Regression: 0.00 MB\n",
      "Decision Tree: 0.53 MB\n",
      "Random Forest: 42.21 MB\n",
      "Gradient Boosting: 0.18 MB\n",
      "K-Nearest Neighbors: 55.83 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Словарь для хранения размера памяти каждой модели\n",
    "model_sizes = {}\n",
    "\n",
    "# Обучение, оценка и измерение размера каждой модели\n",
    "for name, model in models.items():\n",
    "    start_time = time()  # Начало измерения времени\n",
    "    model.fit(X_train, y_train)  # Обучение модели\n",
    "    end_time = time()  # Конец измерения времени\n",
    "    \n",
    "    # Предсказание на тестовом наборе\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Оценка производительности модели\n",
    "    print(f\"\\n{name}:\\n\")\n",
    "    print(f\"Training Time: {end_time - start_time:.2f} seconds\")  # Время обучения\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Временное сохранение модели для определения размера\n",
    "    tmp_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    try:\n",
    "        tmp_file.close()  # Закрытие файла перед использованием\n",
    "        joblib.dump(model, tmp_file.name)\n",
    "        model_size = os.path.getsize(tmp_file.name)  # Размер модели в байтах\n",
    "        model_sizes[name] = model_size / (1024 ** 2)  # Конвертируем в мегабайты\n",
    "    finally:\n",
    "        os.remove(tmp_file.name)  # Удаляем временный файл\n",
    "\n",
    "# Вывод размера памяти каждой модели\n",
    "print(\"\\nModel Sizes (in MB):\")\n",
    "for name, size in model_sizes.items():\n",
    "    print(f\"{name}: {size:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
